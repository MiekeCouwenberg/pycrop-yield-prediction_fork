{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cyp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11656\\3673070283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcyp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMODISExporter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataCleaner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEngineer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcyp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConvModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cyp'"
     ]
    }
   ],
   "source": [
    "# %load run.py\n",
    "from osgeo import gdal\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from cyp.data import MODISExporter, DataCleaner, Engineer\n",
    "from cyp.models import ConvModel, RNNModel\n",
    "\n",
    "import fire\n",
    "\n",
    "\n",
    "class RunTask:\n",
    "    \"\"\"Entry point into the pipeline.\n",
    "\n",
    "    For convenience, all the parameter descriptions are copied from the classes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def export(\n",
    "        export_limit=None,\n",
    "        major_states_only=True,\n",
    "        check_if_done=True,\n",
    "        download_folder=None,\n",
    "        yield_data_path=\"data/yield_data.csv\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Export all the data necessary to train the models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        export_limit: int or None, default=None\n",
    "            If not none, how many .tif files to export (*3, for the image, mask and temperature\n",
    "            files)\n",
    "        major_states_only: boolean, default=True\n",
    "            Whether to only use the 11 states responsible for 75 % of national soybean\n",
    "            production, as is done in the paper\n",
    "        check_if_done: boolean, default=False\n",
    "            If true, will check download_folder for any .tif files which have already been\n",
    "            downloaded, and won't export them again. This effectively allows for\n",
    "            checkpointing, and prevents all files from having to be downloaded at once.\n",
    "        download_folder: None or pathlib Path, default=None\n",
    "            Which folder to check for downloaded files, if check_if_done=True. If None, looks\n",
    "            in data/folder_name\n",
    "        yield_data_path: str, default='data/yield_data.csv'\n",
    "            A path to the yield data\n",
    "        \"\"\"\n",
    "        yield_data_path = Path(yield_data_path)\n",
    "        exporter = MODISExporter(locations_filepath=yield_data_path)\n",
    "        exporter.export_all(\n",
    "            export_limit, major_states_only, check_if_done, download_folder\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def process(\n",
    "        mask_path=\"data/crop_yield-data_mask\",\n",
    "        temperature_path=\"data/crop_yield-data_temperature\",\n",
    "        image_path=\"data/crop_yield-data_image\",\n",
    "        yield_data_path=\"data/yield_data.csv\",\n",
    "        cleaned_data_path=\"data/img_output\",\n",
    "        multiprocessing=False,\n",
    "        processes=4,\n",
    "        parallelism=6,\n",
    "        delete_when_done=False,\n",
    "        num_years=14,\n",
    "        checkpoint=True,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Preprocess the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mask_path: str, default='data/crop_yield-data_mask'\n",
    "            Path to which the mask tif files have been saved\n",
    "        temperature_path: str, default='data/crop_yield-data_temperature'\n",
    "            Path to which the temperature tif files have been saved\n",
    "        image_path: str, default='data/crop_yield-data_image'\n",
    "            Path to which the image tif files have been saved\n",
    "        yield_data_path: str, default='data/yield_data.csv'\n",
    "            Path to the yield data csv file\n",
    "        cleaned_data_path: str, default='data/img_output'\n",
    "            Path to save the data to\n",
    "        multiprocessing: boolean, default=False\n",
    "            Whether to use multiprocessing\n",
    "        processes: int, default=4\n",
    "            Number of processes to use if multiprocessing=True\n",
    "        parallelism: int, default=6\n",
    "            Parallelism if multiprocesisng=True\n",
    "        delete_when_done: boolean, default=False\n",
    "            Whether or not to delete the original .tif files once the .npy array\n",
    "            has been generated.\n",
    "        num_years: int, default=14\n",
    "            How many years of data to create.\n",
    "        checkpoint: boolean, default=True\n",
    "            Whether or not to skip tif files which have already had their .npy arrays\n",
    "            written\n",
    "        \"\"\"\n",
    "        mask_path = Path(mask_path)\n",
    "        temperature_path = Path(temperature_path)\n",
    "        image_path = Path(image_path)\n",
    "        yield_data_path = Path(yield_data_path)\n",
    "        cleaned_data_path = Path(cleaned_data_path)\n",
    "\n",
    "        cleaner = DataCleaner(\n",
    "            mask_path,\n",
    "            temperature_path,\n",
    "            image_path,\n",
    "            yield_data_path,\n",
    "            savedir=cleaned_data_path,\n",
    "            multiprocessing=multiprocessing,\n",
    "            processes=processes,\n",
    "            parallelism=parallelism,\n",
    "        )\n",
    "        cleaner.process(\n",
    "            delete_when_done=delete_when_done,\n",
    "            num_years=num_years,\n",
    "            checkpoint=checkpoint,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def engineer(\n",
    "        cleaned_data_path=\"data/img_output\",\n",
    "        yield_data_path=\"data/yield_data.csv\",\n",
    "        county_data_path=\"data/county_data.csv\",\n",
    "        num_bins=32,\n",
    "        max_bin_val=4999,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Take the preprocessed data and generate the input to the models\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cleaned_data_path: str, default='data/img_output'\n",
    "            Path to save the data to, and path to which processed data has been saved\n",
    "        yield_data_path: str, default='data/yield_data.csv'\n",
    "            Path to the yield data csv file\n",
    "        county_data_path: str, default='data/county_data.csv'\n",
    "            Path to the county data csv file\n",
    "        num_bins: int, default=32\n",
    "            If generate=='histogram', the number of bins to generate in the histogram.\n",
    "        max_bin_val: int, default=4999\n",
    "            The maximum value of the bins. The default is taken from the original paper;\n",
    "            note that the maximum pixel values from the MODIS datsets range from 16000 to\n",
    "            18000 depending on the band\n",
    "        \"\"\"\n",
    "        cleaned_data_path = Path(cleaned_data_path)\n",
    "        yield_data_path = Path(yield_data_path)\n",
    "        county_data_path = Path(county_data_path)\n",
    "\n",
    "        engineer = Engineer(cleaned_data_path, yield_data_path, county_data_path)\n",
    "        engineer.process(\n",
    "            num_bands=9,\n",
    "            generate=\"histogram\",\n",
    "            num_bins=num_bins,\n",
    "            max_bin_val=max_bin_val,\n",
    "            channels_first=True,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def train_cnn(\n",
    "        cleaned_data_path=Path(\"data/img_output\"),\n",
    "        dropout=0.5,\n",
    "        dense_features=None,\n",
    "        savedir=Path(\"data/models\"),\n",
    "        times=\"all\",\n",
    "        pred_years=None,\n",
    "        num_runs=2,\n",
    "        train_steps=25000,\n",
    "        batch_size=32,\n",
    "        starter_learning_rate=1e-3,\n",
    "        weight_decay=1,\n",
    "        l1_weight=0,\n",
    "        patience=10,\n",
    "        use_gp=True,\n",
    "        sigma=1,\n",
    "        r_loc=0.5,\n",
    "        r_year=1.5,\n",
    "        sigma_e=0.32,\n",
    "        sigma_b=0.01,\n",
    "        device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train a CNN model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cleaned_data_path: str, default='data/img_output'\n",
    "            Path to which histogram has been saved\n",
    "        dropout: float, default=0.5\n",
    "            Default taken from the original paper\n",
    "        dense_features: list, or None, default=None.\n",
    "            output feature size of the Linear layers. If None, default values will be taken from the paper.\n",
    "            The length of the list defines how many linear layers are used.\n",
    "        savedir: pathlib Path, default=Path('data/models')\n",
    "            The directory into which the models should be saved.\n",
    "        times: {'all', 'realtime'}\n",
    "            Which time indices to train the model on. If 'all', a full run (32 timesteps) is used.\n",
    "            If 'realtime', range(10, 31, 4) is used.\n",
    "        pred_years: int or None, default=None\n",
    "            Which year to build models for. If None, the default values from the paper (range(2009, 2016))\n",
    "            are used.\n",
    "        num_runs: int, default=2\n",
    "            The number of runs to do per year. Default taken from the paper\n",
    "        train_steps: int, default=25000\n",
    "            The number of steps for which to train the model. Default taken from the paper.\n",
    "        batch_size: int, default=32\n",
    "            Batch size when training. Default taken from the paper\n",
    "        starter_learning_rate: float, default=1e-3\n",
    "            Starter learning rate. Note that the learning rate is divided by 10 after 2000 and 4000 training\n",
    "            steps. Default taken from the paper\n",
    "        weight_decay: float, default=1\n",
    "            Weight decay (L2 regularization) on the model weights\n",
    "        l1_weight: float, default=0\n",
    "            In addition to MSE, L1 loss is also used (sometimes). The default is 0, but a value of 1.5 is used\n",
    "            when training the model in batch\n",
    "        patience: int or None, default=10\n",
    "            The number of epochs to wait without improvement in the validation loss before terminating training.\n",
    "            Note that the original repository doesn't use early stopping.\n",
    "\n",
    "        use_gp: boolean, default=True\n",
    "            Whether to use a Gaussian process in addition to the model\n",
    "\n",
    "        If use_gp=True, the following parameters are also used:\n",
    "\n",
    "        sigma: float, default=1\n",
    "            The kernel variance, or the signal variance\n",
    "        r_loc: float, default=0.5\n",
    "            The length scale for the location data (latitudes and longitudes)\n",
    "        r_year: float, default=1.5\n",
    "            The length scale for the time data (years)\n",
    "        sigma_e: float, default=0.32\n",
    "            Noise variance. 0.32 **2 ~= 0.1\n",
    "        sigma_b: float, default=0.01\n",
    "            Parameter variance; the variance on B\n",
    "\n",
    "        device: torch.device\n",
    "            Device to run model on. By default, checks for a GPU. If none exists, uses\n",
    "            the CPU\n",
    "\n",
    "        \"\"\"\n",
    "        histogram_path = Path(cleaned_data_path) / \"histogram_all_full.npz\"\n",
    "\n",
    "        model = ConvModel(\n",
    "            in_channels=9,\n",
    "            dropout=dropout,\n",
    "            dense_features=dense_features,\n",
    "            savedir=savedir,\n",
    "            use_gp=use_gp,\n",
    "            sigma=sigma,\n",
    "            r_loc=r_loc,\n",
    "            r_year=r_year,\n",
    "            sigma_e=sigma_e,\n",
    "            sigma_b=sigma_b,\n",
    "            device=device,\n",
    "        )\n",
    "        model.run(\n",
    "            histogram_path,\n",
    "            times,\n",
    "            pred_years,\n",
    "            num_runs,\n",
    "            train_steps,\n",
    "            batch_size,\n",
    "            starter_learning_rate,\n",
    "            weight_decay,\n",
    "            l1_weight,\n",
    "            patience,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def train_rnn(\n",
    "        cleaned_data_path=\"data/img_output\",\n",
    "        num_bins=32,\n",
    "        hidden_size=128,\n",
    "        rnn_dropout=0.75,\n",
    "        dense_features=None,\n",
    "        savedir=Path(\"data/models\"),\n",
    "        times=\"all\",\n",
    "        pred_years=None,\n",
    "        num_runs=2,\n",
    "        train_steps=10000,\n",
    "        batch_size=32,\n",
    "        starter_learning_rate=1e-3,\n",
    "        weight_decay=0,\n",
    "        l1_weight=0,\n",
    "        patience=10,\n",
    "        use_gp=True,\n",
    "        sigma=1,\n",
    "        r_loc=0.5,\n",
    "        r_year=1.5,\n",
    "        sigma_e=0.32,\n",
    "        sigma_b=0.01,\n",
    "        device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Train an RNN model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        cleaned_data_path: str, default='data/img_output'\n",
    "            Path to which histogram has been saved\n",
    "        num_bins: int, default=32\n",
    "            Number of bins in the generated histogram\n",
    "        hidden_size: int, default=128\n",
    "            The size of the hidden state. Default taken from the original paper\n",
    "        rnn_dropout: float, default=0.75\n",
    "            Default taken from the original paper. Note that this dropout is applied to the\n",
    "            hidden state after each timestep, not after each layer (since there is only one layer)\n",
    "        dense_features: list, or None, default=None.\n",
    "            output feature size of the Linear layers. If None, default values will be taken from the paper.\n",
    "            The length of the list defines how many linear layers are used.\n",
    "        savedir: pathlib Path, default=Path('data/models')\n",
    "            The directory into which the models should be saved.\n",
    "        times: {'all', 'realtime'}\n",
    "            Which time indices to train the model on. If 'all', a full run (32 timesteps) is used.\n",
    "            If 'realtime', range(10, 31, 4) is used.\n",
    "        pred_years: int or None, default=None\n",
    "            Which years to build models for. If None, the default values from the paper (range(2009, 2016))\n",
    "            are used.\n",
    "        num_runs: int, default=2\n",
    "            The number of runs to do per year. Default taken from the paper\n",
    "        train_steps: int, default=10000\n",
    "            The number of steps for which to train the model. Default taken from the paper.\n",
    "        batch_size: int, default=32\n",
    "            Batch size when training. Default taken from the paper\n",
    "        starter_learning_rate: float, default=1e-3\n",
    "            Starter learning rate. Note that the learning rate is divided by 10 after 2000 and 4000 training\n",
    "            steps. Default taken from the paper\n",
    "        weight_decay: float, default=1\n",
    "            Weight decay (L2 regularization) on the model weights\n",
    "        l1_weight: float, default=0\n",
    "            L1 loss is not used for the RNN. Setting it to 0 avoids it being computed.\n",
    "        patience: int or None, default=10\n",
    "            The number of epochs to wait without improvement in the validation loss before terminating training.\n",
    "            Note that the original repository doesn't use early stopping.\n",
    "\n",
    "        use_gp: boolean, default=True\n",
    "            Whether to use a Gaussian process in addition to the model\n",
    "\n",
    "        If use_gp=True, the following parameters are also used:\n",
    "\n",
    "        sigma: float, default=1\n",
    "            The kernel variance, or the signal variance\n",
    "        r_loc: float, default=0.5\n",
    "            The length scale for the location data (latitudes and longitudes)\n",
    "        r_year: float, default=1.5\n",
    "            The length scale for the time data (years)\n",
    "        sigma_e: float, default=0.32\n",
    "            Noise variance. 0.32 **2 ~= 0.1\n",
    "        sigma_b: float, default=0.01\n",
    "            Parameter variance; the variance on B\n",
    "\n",
    "        device: torch.device\n",
    "            Device to run model on. By default, checks for a GPU. If none exists, uses\n",
    "            the CPU\n",
    "\n",
    "        \"\"\"\n",
    "        histogram_path = Path(cleaned_data_path) / \"histogram_all_full.npz\"\n",
    "\n",
    "        model = RNNModel(\n",
    "            in_channels=9,\n",
    "            num_bins=num_bins,\n",
    "            hidden_size=hidden_size,\n",
    "            rnn_dropout=rnn_dropout,\n",
    "            dense_features=dense_features,\n",
    "            savedir=savedir,\n",
    "            use_gp=use_gp,\n",
    "            sigma=sigma,\n",
    "            r_loc=r_loc,\n",
    "            r_year=r_year,\n",
    "            sigma_e=sigma_e,\n",
    "            sigma_b=sigma_b,\n",
    "            device=device,\n",
    "        )\n",
    "        model.run(\n",
    "            histogram_path,\n",
    "            times,\n",
    "            pred_years,\n",
    "            num_runs,\n",
    "            train_steps,\n",
    "            batch_size,\n",
    "            starter_learning_rate,\n",
    "            weight_decay,\n",
    "            l1_weight,\n",
    "            patience,\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fire.Fire(RunTask)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31d2f900fc099c7e084caa42a996cce166aa7274d5200c628b661807f9e39937"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('crop_yield_prediction')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
